# 0. Что изменилось по сравнению с предыдущей схемой (Схема Гагарин А.Ю.drawio из ДЗ1)

1. **Auth / User**
   - Выделен отдельный **User Service** для хранения профилей и ролей (RBAC).
   - **Auth Service** теперь отвечает только за аутентификацию и выдачу токенов.

2. **File Service**
   - Добавлен сервис для работы с файлами.
   - Поддержка проверки на вирусы и хранение в объектном хранилище (S3/MinIO).

3. **Comment Service**
   - Добавлен сервис для переписки по заявкам (онлайн-чат/комментарии).
   - Публикует события в Kafka.

4. **Request Service**
   - Теперь публикует события (создание/изменение статуса) в Kafka.
   - CQRS обозначен как опциональный (можно убрать для MVP).

5. **Notification Service**
   - Ранее — синхронные вызовы.
   - Теперь — подписка на Kafka, масштабируемые Notification Workers.

6. **Reporting Service**
   - Новый сервис для анализа SLA и дисциплины выполнения.
   - Получает данные из Request DB, Kafka и Monitoring.

7. **Monitoring & Logging**
   - Добавлены системы сбора метрик и логов для всех сервисов.

8. **Admin Panel**
   - Теперь работает через API Gateway.
   - Имеет доступ к User Service и Reporting Service, а не только к заявкам.

9. **Rate Limiter**
   - Добавлен перед API Gateway для защиты от перегрузок и DDoS.

10. **Связи**
   - Сервисы общаются через Kafka для событий, вместо прямых вызовов.
   - File Service теперь доступен через API Gateway для пользователей.
   - Reporting Service связан не только с Monitoring, но и с Request DB/Kafka.
   - Admin Panel имеет более широкую интеграцию (Users, Requests, Reports).

---

# Домашнее задание  
## Проектирование и оптимизация отказоустойчивой и масштабируемой системы

### 1. Масштабирование системы

#### Выбор подхода
- **Горизонтальное масштабирование** выбрано в качестве основного подхода.  
  - Вертикальное масштабирование ограничено ресурсами одного узла и плохо подходит для высокой нагрузки.  
  - Горизонтальное масштабирование (масштабирование сервисов, БД и брокера сообщений) обеспечивает эластичность, независимость компонентов и отказоустойчивость.

#### Применяемые техники:
- **API Gateway** и сервисы — репликация и балансировка через load balancer.  
- **Базы данных** — репликация (master-replica) + шардинг для масштабирования по объёму.  
- **Kafka** — кластер из нескольких брокеров с репликацией партиций.  
- **Redis** — кластерный режим (Redis Cluster) для горизонтального масштабирования.  

#### CAP-теорема:
- Для сервисов заявок и пользователей — приоритет **Согласованности (C)** и **Доступности (A)**, допускаем сниженное **Устойчивое разделение (P)** при сетевых сбоях.  
- Для Kafka и Redis — баланс: Eventual Consistency, но высокая доступность.  

---

### 2. Обеспечение высокой доступности

#### Основные подходы:
- Балансировка нагрузки (Nginx / HAProxy).  
- Репликация сервисов в нескольких зонах доступности.  
- Автоматический failover для БД и брокеров.  
- Использование Health Checks и self-healing.  

#### Сценарии отказов:
1. **Отказ сервиса** → балансировщик исключает его из пула, запросы идут к другим инстансам.  
2. **Отказ БД (master)** → переключение на реплику, задержка минимальна.  
3. **Отказ Kafka-брокера** → перераспределение лидеров партиций, потребители продолжают работать.  
4. **Отказ API Gateway** → резервный узел/кластер подхватывает нагрузку.  

#### Рекомендации:
- Разворачивать компоненты в нескольких зонах доступности.  
- Использовать отказоустойчивые механизмы (replication, auto-restart, monitoring).  

---

### 3. Оптимизация производительности

#### Потенциальные узкие места:
- Высокая нагрузка на Request DB при массовом чтении.  
- Уведомления и комментарии при пиковых нагрузках.  
- API Gateway при наплыве пользователей.  

#### Методы оптимизации:
- **Индексация** по ключевым полям (ID заявки, статус, пользователь).  
- **Batch-операции** для массовых вставок (например, логирование).  
- **Кэширование**:
  - Redis для часто читаемых данных (списки заявок, профили пользователей).  
  - HTTP-level кэширование.  
- **CQRS** — разделение чтения и записи в Request Service.  
- **Async-processing** через Kafka для тяжёлых задач (уведомления, отчёты).  

#### Профиль производительности (шаблон):
| Компонент | Метрика | Норма | Узкое место | Оптимизация |
|-----------|---------|-------|-------------|-------------|
| Request Service | Response Time | <500 мс | рост до 1с при 10k rps | кэширование + CQRS |
| DB | Query Time | <50 мс | медленные SELECT | индексация, шардинг |
| Kafka | Latency | <10 мс | задержки при перегрузке | больше брокеров |
| API Gateway | Throughput | >50k rps | узкое место на пике | масштабирование, rate limiter |

---

### 4. Мониторинг и профилирование

#### План мониторинга:
- **Инфраструктурные метрики**: CPU, RAM, Disk, Network.  
- **Метрики сервисов**: Response Time, Error Rate, Throughput.  
- **Метрики БД**: медленные запросы, задержка репликации.  
- **Kafka**: lag по топикам, задержки обработки.  
- **Redis**: cache hit ratio.  

#### Инструменты:
- **Prometheus** для сбора метрик.  
- **Grafana** для дашбордов и алертов.  
- **ELK (Elasticsearch + Logstash + Kibana)** или Loki для логов.  
- **Jaeger / OpenTelemetry** для трассировки запросов.  

#### Сценарий анализа:
- Если растёт **Response Time** → проверяем latency DB/Kafka.  
- Если увеличивается **Error Rate** → смотрим логи сервисов + алерты.  
- Если снижается **Throughput** → проверяем балансировщик и нагрузку на API Gateway.  

---

### 5. Результаты

#### Диаграмма архитектуры
- Система построена на **горизонтальном масштабировании**.  
- Используются балансировщики, кластеризация Kafka и Redis, репликация БД.  
- Все сервисы независимы, соединяются через API Gateway и Kafka.  

#### Документ
- Подробное описание решений по масштабированию, отказоустойчивости, оптимизации и мониторингу.  

#### Профиль производительности
- Таблица с метриками, нормами и предложенными улучшениями.  

---